import streamlit as st
import numpy as np
import tempfile
import os
from pydub import AudioSegment
import sounddevice as sd
import time
import logging
import whisper

# ãƒ­ã‚¬ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
logger = logging.getLogger(__name__)

# è¨­å®š
SAMPLE_RATE = 16000  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ (Hz)
DEFAULT_RECORD_DURATION = 5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŒ²éŸ³æ™‚é–“ (ç§’)

# WhisperéŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
@st.cache_resource
def load_whisper_model(model_size="base"):
    """Whisperãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹"""
    return whisper.load_model(model_size)

def record_audio_device(duration=DEFAULT_RECORD_DURATION):
    """
    sounddeviceã‚’ä½¿ç”¨ã—ãŸãƒã‚¤ã‚¯éŒ²éŸ³æ©Ÿèƒ½
    duration: éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
    æˆ»ã‚Šå€¤: èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€ã¾ãŸã¯ Noneï¼ˆã‚­ãƒ£ãƒ³ã‚»ãƒ«æ™‚ï¼‰
    """
    # ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ãƒˆã‚’ç¢ºèª
    if "recording_state" not in st.session_state:
        st.session_state.recording_state = "inactive"
        st.session_state.recognized_text = None
    
    # Whisperãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã‚‹ã®ã§åŠ¹ç‡çš„ï¼‰
    whisper_model = load_whisper_model()
    
    # UIç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    status_placeholder = st.empty()
    button_col1, button_col2 = st.columns(2)
    text_placeholder = st.empty()
    
    # éŒ²éŸ³å®Œäº†å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢
    if st.session_state.recording_state == "completed" and st.session_state.recognized_text:
        text_placeholder.success(f"èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: {st.session_state.recognized_text}")
    
    # éŒ²éŸ³çŠ¶æ…‹ã«å¿œã˜ãŸUIã®è¡¨ç¤º
    if st.session_state.recording_state == "inactive":
        status_placeholder.info("ğŸ¤ ã€ŒéŒ²éŸ³é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€è‹±èªã§è©±ã—ã¦ãã ã•ã„")
    elif st.session_state.recording_state == "recording":
        status_placeholder.warning("ğŸ”´ éŒ²éŸ³ä¸­... è‹±èªã§è©±ã—ã¦ãã ã•ã„")
    elif st.session_state.recording_state == "processing":
        status_placeholder.info("â³ éŸ³å£°ã‚’å‡¦ç†ä¸­...")
    elif st.session_state.recording_state == "completed":
        if st.session_state.recognized_text:
            status_placeholder.success("âœ… éŸ³å£°èªè­˜å®Œäº†ï¼")
        else:
            status_placeholder.error("âŒ éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ãã ã•ã„ã€‚")
    
    # éŒ²éŸ³é–‹å§‹ãƒœã‚¿ãƒ³
    if button_col1.button("ğŸ¤ éŒ²éŸ³é–‹å§‹", type="primary", disabled=st.session_state.recording_state == "recording"):
        st.session_state.recording_state = "recording"
        
        with st.spinner(f"{duration}ç§’é–“éŒ²éŸ³ä¸­..."):
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
            progress_bar = st.progress(0)
            
            # éŸ³å£°éŒ²éŸ³
            audio_data = sd.rec(
                int(duration * SAMPLE_RATE),
                samplerate=SAMPLE_RATE, 
                channels=1,
                dtype='float32'
            )
            
            # éŒ²éŸ³ä¸­ã®é€²æ—è¡¨ç¤º
            for i in range(duration):
                # é€²æ—ãƒãƒ¼ã‚’æ›´æ–°
                progress_bar.progress((i + 1) / duration)
                time.sleep(1)
                
            sd.wait()  # éŒ²éŸ³å®Œäº†ã¾ã§å¾…æ©Ÿ
            
            # çŠ¶æ…‹æ›´æ–°
            st.session_state.recording_state = "processing"
            status_placeholder.info("â³ éŸ³å£°ã‚’å‡¦ç†ä¸­...")
            
            try:
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
                with st.spinner("éŸ³å£°ã‚’å‡¦ç†ä¸­..."):
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
                    audio_data = audio_data.flatten()
                    
                    # éŸ³é‡ã‚’å¢—å¹…
                    audio_data = audio_data * 1.5
                    
                    # int16å½¢å¼ã«å¤‰æ›ï¼ˆWAVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ç”¨ï¼‰
                    audio_int16 = (audio_data * 32767).astype(np.int16)
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                        temp_filename = f.name
                    
                    # pydubã§AudioSegmentã«å¤‰æ›ã—ã¦ä¿å­˜
                    audio_segment = AudioSegment(
                        audio_int16.tobytes(),
                        frame_rate=SAMPLE_RATE,
                        sample_width=2,
                        channels=1
                    )
                    
                    # éŸ³é‡ã‚’å¢—å¹…ã—ã¦èªè­˜ç²¾åº¦ã‚’å‘ä¸Š
                    audio_segment = audio_segment + 15  # 15dBå¢—å¹…
                    
                    # ãƒã‚¤ã‚ºãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³
                    audio_segment = audio_segment.strip_silence(
                        silence_len=300,  # 300msä»¥ä¸Šã®ç„¡éŸ³ã‚’ç„¡è¦–
                        silence_thresh=-35,  # -35dBä»¥ä¸‹ã‚’ç„¡éŸ³ã¨åˆ¤æ–­
                        padding=200  # å‰å¾Œã«200msã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¿½åŠ 
                    )
                    
                    audio_segment.export(temp_filename, format="wav")
                
                # Whisperãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹éŸ³å£°èªè­˜
                with st.spinner("Whisperã§éŸ³å£°ã‚’åˆ†æä¸­..."):
                    # éŸ³å£°èªè­˜å®Ÿè¡Œ
                    result = whisper_model.transcribe(
                        temp_filename,
                        language="en",
                        fp16=False,
                        temperature=0.0,
                        condition_on_previous_text=False
                    )
                    
                    recognized_text = result["text"].strip()
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.unlink(temp_filename)
                    
                    if recognized_text:
                        st.session_state.recognized_text = recognized_text
                    else:
                        st.session_state.recognized_text = None
                        raise Exception("éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚‚ã†å°‘ã—å¤§ããªå£°ã§ã¯ã£ãã‚Šã¨è©±ã—ã¦ãã ã•ã„ã€‚")
                
                st.session_state.recording_state = "completed"
                st.rerun()
                
            except Exception as e:
                logger.error(f"éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼: {e}")
                st.session_state.recording_state = "completed"
                st.session_state.recognized_text = None
                st.rerun()
    
    # éŒ²éŸ³ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³
    if button_col2.button("â¹ï¸ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", disabled=st.session_state.recording_state != "recording"):
        st.session_state.recording_state = "inactive"
        st.rerun()
    
    # ç¾åœ¨ã®çŠ¶æ…‹ã«å¿œã˜ã¦çµæœã‚’è¿”ã™
    if st.session_state.recording_state == "completed" and st.session_state.recognized_text:
        return st.session_state.recognized_text
    return None

def record_audio_text():
    """
    ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    æˆ»ã‚Šå€¤: å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€ã¾ãŸã¯ Noneï¼ˆã‚­ãƒ£ãƒ³ã‚»ãƒ«æ™‚ï¼‰
    """
    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºç”¨
    error_placeholder = st.empty()
    
    # å…¥åŠ›çŠ¶æ…‹è¡¨ç¤º
    status_placeholder = st.empty()
    status_placeholder.info("ğŸ–Šï¸ è‹±èªã§å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    
    try:
        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
        user_input = st.text_input("è‹±èªã§å›ç­”ã‚’å…¥åŠ›:", key="voice_replacement_input")
        
        if st.button("å›ç­”ã‚’é€ä¿¡", key="submit_text_answer"):
            if user_input:
                # å…¥åŠ›å®Œäº†è¡¨ç¤º
                status_placeholder.success("âœ“ å›ç­”ã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸï¼")
                return user_input
            else:
                error_placeholder.error("ãƒ†ã‚­ã‚¹ãƒˆãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                return None
            
    except Exception as e:
        error_placeholder.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
    # å…¥åŠ›ãŒãªã„å ´åˆã¯Noneã‚’è¿”ã™
    return None

def record_audio():
    """
    éŸ³å£°å…¥åŠ›ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’æä¾›ã™ã‚‹é–¢æ•°
    æˆ»ã‚Šå€¤: èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€ã¾ãŸã¯ None
    """
    # ã‚¿ãƒ–ã‚’ä½œæˆã—ã¦éŸ³å£°å…¥åŠ›ã¨ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ã«
    tab1, tab2 = st.tabs(["ğŸ¤ éŸ³å£°ã§å›ç­”", "âŒ¨ï¸ ãƒ†ã‚­ã‚¹ãƒˆã§å›ç­”"])
    
    with tab1:
        result = record_audio_device()
        if result:
            return result
    
    with tab2:
        result = record_audio_text()
        if result:
            return result
    
    return None

def voice_input_button():
    """
    å›ç­”å…¥åŠ›ãƒœã‚¿ãƒ³ã¨ãã®å‡¦ç†ã‚’æä¾›ã™ã‚‹é–¢æ•°
    æˆ»ã‚Šå€¤: å…¥åŠ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã€ã¾ãŸã¯ Noneï¼ˆæœªå…¥åŠ›æ™‚ã‚„ã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
    """
    if st.button("ğŸ¤ å›ç­”ã™ã‚‹", type="primary", key="voice_input_button"):
        # éŸ³å£°ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’å®Ÿè¡Œ
        recognized_text = record_audio()
        
        # å…¥åŠ›çµæœã‚’è¿”ã™
        return recognized_text
    
    # ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¦ã„ãªã„å ´åˆã¯Noneã‚’è¿”ã™
    return None 